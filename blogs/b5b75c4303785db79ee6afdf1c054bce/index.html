<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="生成AI・LLM関連の取り組みをしている会社・個人のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="author" content="r-kagaya"><meta name="robots" content="index, follow"><meta property="og:url" content="https://r-kagaya.github.io/llm-tech-blog-rss-feed/"><meta property="og:title" content="Chip Huyenのフィード｜生成AI・LLM関連テックブログRSS"><meta property="og:image" content="https://r-kagaya.github.io/llm-tech-blog-rss-feed/images/og-image.png"><meta property="og:description" content="生成AI・LLM関連の取り組みをしている会社・個人のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta property="og:type" content="website"><meta property="og:site_name" content="生成AI・LLM関連テックブログRSS"><meta name="twitter:card" content="summary"><meta property="twitter:domain" 
content="https://r-kagaya.github.io/llm-tech-blog-rss-feed/"><meta property="twitter:url" content="https://r-kagaya.github.io/llm-tech-blog-rss-feed/"><meta name="twitter:title" content="Chip Huyenのフィード｜生成AI・LLM関連テックブログRSS"><meta name="twitter:description" content="生成AI・LLM関連の取り組みをしている会社・個人のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="twitter:image" content="https://r-kagaya.github.io/llm-tech-blog-rss-feed/images/og-image.png"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><style>
*,::after,::before{box-sizing:border-box}*{margin:0}body,html{height:100%}body{line-height:1.5;-webkit-font-smoothing:antialiased}canvas,img,picture,svg,video{display:block;max-width:100%}button,input,select,textarea{font:inherit}h1,h2,h3,h4,h5,h6,p{overflow-wrap:break-word}#__next,#root{isolation:isolate}:root{--ui-color-brand:#353535;--ui-color-n-000:#fff;--ui-color-n-100:#ebebeb;--ui-color-n-300:#aeaeae;--ui-color-n-500:#353535;--ui-color-n-700:#282828;--ui-color-n-900:#1a1a1a;--ui-color-background-primary:var(--ui-color-n-000);--ui-color-form-input:var(--ui-color-n-100);--ui-color-typography-heading:var(--ui-color-n-500);--ui-color-typography-body:var(--ui-color-n-900);--ui-color-typography-note:var(--ui-color-n-300);--ui-color-typography-button:var(--ui-color-n-000);--ui-typography-typeface:"Inter",sans-serif;--ui-typography-h1:1.9375rem;--ui-typography-h2:1.5625rem;--ui-typography-h3:1.25rem;--ui-typography-p:1rem;--ui-typography-s:.8125rem;--ui-typography-h1-leading:1.2;--ui-typography-h2-leading:1.2;--ui-typography-h3-leading:1.25;--ui-typography-p-leading:1.5;--ui-typography-margin-heading:.75rem;--ui-typography-margin-body:1.125rem;--ui-layout-container:1.25rem;--ui-layout-grid:3.625rem;--ui-layout-gutter:1rem;--ui-gap-cta:.75rem;--ui-gap-content:2rem;--ui-radius-button:5rem;--ui-radius-input:5rem}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}body{background-color:var(--ui-color-background-primary);color:var(--ui-color-typography-body);font-family:var(--ui-typography-typeface);font-feature-settings:"liga","kern";font-size:var(--ui-typography-p);font-weight:400;line-height:var(--ui-typography-p-leading);margin:0 auto;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased}a{color:var(--ui-color-brand);text-decoration:none}h1,h2,h3,p{margin-top:0}h1,h2,h3{color:var(--ui-color-typography-heading);margin-bottom:var(--ui-typography-margin-heading)}h1{font-size:var(--ui-typography-h1);line-height:var(--ui-typography-h1-leading)}h2{font-size:var(--ui-typography-h2);line-height:var(--ui-typography-h2-leading)}h3{font-size:var(--ui-typography-h3);line-height:var(--ui-typography-h3-leading)}p{margin-bottom:var(--ui-typography-margin-body)}p:last-child{margin-bottom:0}strong{font-weight:700}small{font-size:var(--ui-typography-s)}.ui-text-note{color:var(--ui-color-typography-note);line-height:1}img,svg{display:block;height:auto;margin:0 auto;max-width:100%}.ui-layout-container{padding-left:var(--ui-layout-container);padding-right:var(--ui-layout-container)}.ui-layout-flex,.ui-layout-grid{align-items:center;justify-content:center}.ui-layout-flex{display:flex}.ui-layout-grid{display:grid}.ui-component-cta{flex-direction:column;row-gap:var(--ui-gap-cta)}button,input{color:inherit;font-family:inherit;font-size:var(--ui-typography-p);line-height:1;margin:0;outline:0;text-rendering:inherit;text-transform:none}form{width:100%}.ui-component-form{background-color:var(--ui-color-form-input);border-radius:var(--ui-radius-input);grid-template-columns:minmax(0,1fr) auto;padding:.25rem}::placeholder{color:var(--ui-color-typography-note)}.ui-component-input{background-color:var(--ui-color-form-input);border:.0625rem solid var(--ui-color-form-input);border-radius:var(--ui-radius-input)}.ui-component-input-medium{height:2.5rem;padding:.625rem 1rem .75rem}button{background:0 0;border:0;cursor:pointer;display:block;padding:0}.ui-component-button{border:.0625rem solid var(--ui-color-brand);border-radius:var(--ui-radius-button);display:block;font-weight:700;line-height:1;text-align:center}.ui-component-button-primary{background-color:var(--ui-color-brand);color:var(--ui-color-typography-button)}.ui-component-button-medium{padding:.625rem .875rem .75rem;width:fit-content}.ui-section-header{padding-bottom:1.25rem;padding-top:1.25rem}.ui-section-header__layout{justify-content:space-between}.ui-section-content{padding-bottom:2em;padding-top:5rem;text-align:center}.ui-section-content--image{margin-bottom:var(--ui-gap-content);margin-top:var(--ui-gap-content)}.ui-section-content--feature{row-gap:var(--ui-gap-content)}.ui-section-content--icon{margin-bottom:1rem}.ui-section-close{padding-bottom:5rem;padding-top:5rem;text-align:center}.ui-section-footer{padding-bottom:1.25rem;padding-top:1.25rem}.ui-section-footer__layout{column-gap:var(--ui-layout-gutter)}.ui-section-footer--copyright{margin-bottom:0;margin-right:auto}@media screen and (min-width:48rem){:root{--ui-typography-h1:2.1875rem;--ui-typography-h2:1.75rem;--ui-typography-h3:1.4375rem;--ui-typography-p:1.125rem;--ui-typography-s:.875rem;--ui-typography-margin-body:1.25rem;--ui-layout-container:4.25rem;--ui-layout-gutter:1.5rem;--ui-gap-content:3rem}.ui-layout-column-center,.ui-layout-container{margin-left:auto;margin-right:auto}.ui-layout-grid-3{column-gap:var(--ui-layout-gutter);grid-template-columns:repeat(2,1fr);justify-items:center}.ui-layout-grid-3 div:last-of-type{left:calc(50% + (var(--ui-layout-gutter)/ 2));position:relative}.ui-layout-column-4{width:calc((var(--ui-layout-grid) * 4) + (var(--ui-layout-gutter) * 3))}.ui-layout-column-6{width:calc((var(--ui-layout-grid) * 6) + (var(--ui-layout-gutter) * 5))}.ui-section-header{padding-bottom:2rem;padding-top:2rem}.ui-section-content{padding-bottom:3rem}.ui-section-content--icon{height:4rem;width:4rem}.ui-section-footer{padding-bottom:2rem;padding-top:2rem}}@media screen and (min-width:64rem){:root{--ui-layout-container:0}a{transition:all 250ms ease}a:not(.ui-component-button):hover{color:var(--ui-color-typography-body)}.ui-layout-container{width:60rem}.ui-layout-grid-3{grid-template-columns:repeat(3,1fr)}.ui-layout-grid-3 div:last-of-type{position:static}}@media screen and (min-width:75rem){:root{--ui-typography-h1:2.75rem;--ui-typography-h2:2.1875rem;--ui-typography-h3:1.75rem;--ui-typography-h4:1.4375rem;--ui-typography-margin-heading:1rem;--ui-typography-margin-body:1.75rem;--ui-layout-grid:4rem;--ui-layout-gutter:2rem;--ui-gap-content:4rem}.ui-text-intro{font-size:var(--ui-typography-h4)}.ui-layout-container{width:70rem}.ui-section-header{padding-bottom:3rem;padding-top:3rem}.ui-section-content{padding-bottom:5rem;padding-top:7.5rem}.ui-section-content--icon{height:5rem;margin-bottom:1.125rem;width:5rem}.ui-section-close{padding-bottom:7.5rem;padding-top:7.5rem}.ui-section-footer{padding-bottom:3rem;padding-top:3rem}}:root{--material-color-yellow-50:#fffde7;--material-color-yellow-100:#fff9c4;--material-color-orange-500:#ff9800;--material-color-orange-600:#fb8c00;--base-background:#fff;--base-color:#333;--base-color-lighter:#777;--base-color-muted:#999;--yellow-background:var(--material-color-yellow-100);--yellow-background-lighter:var(--material-color-yellow-50);--orange-background-dark:var(--material-color-orange-500);--orange-background-dark-active:var(--material-color-orange-600);--hatena-color:#01a5df;--base-font:-apple-system,BlinkMacSystemFont,Helvetica Neue,Yu Gothic,YuGothic,Verdana,Meiryo,M+ 1p,sans-serif;--ui-gap-content:2em}.ui-text-note{color:var(--base-color-muted)}.ui-section-header__layout img{display:inline-block;width:24px;height:24px;vertical-align:middle}.ui-section-content{padding-top:2.5em;padding-bottom:3.5rem}.ui-section-header{padding-top:2rem;padding-bottom:1rem}.ui-component-form{border-radius:0;grid-template-columns:auto minmax(0,1fr) auto}.ui-component-form .ui-component-button{border-radius:0;background:var(--orange-background-dark);border-color:var(--orange-background-dark)}.ui-component-form .ui-component-button.active{background:var(--orange-background-dark-active);border-color:var(--orange-background-dark-active)}@media screen and (min-width:48rem){.ui-layout-grid-3 div:last-of-type{left:0}}@media screen and (min-width:75rem){.ui-layout-grid-3{grid-template-columns:repeat(4,1fr)}}.ui-typography-heading{text-align:left}.ui-typography-heading small{color:var(--base-color-muted)}img{color:var(--base-color-muted)}.ui-section-header__layout .ui-section-header__title{display:inline-block;line-height:22px;vertical-align:middle;font-weight:700;font-size:1.3em;color:var(--base-color)}.ui-top-section{padding-bottom:2em}.ui-component-form__label{margin-left:.2em}.ui-component-form__label img{width:32px;height:32px}.ui-component-form__label span{font-weight:700}.ui-top-section .ui-text-note{margin-bottom:.6em}.ui-top-section .ui-top-section__subscribe{margin-top:.3em;display:flex;gap:.5em}.ui-top-section .ui-top-section__subscribe img{height:37px;width:auto}.ui-section-nav__layout{justify-content:start}.ui-section-nav__link{font-weight:700;margin-right:1.5em;padding:.5em 0;border-bottom:2px solid transparent;color:var(--base-color-muted)}.ui-section-nav__link--active{color:var(--base-color);border-bottom-color:var(--base-color)}.ui-section-content__feed-date-heading{text-align:left;font-size:1.2em;color:var(--base-color-lighter);margin-top:1em;margin-bottom:1em;padding:.4em .3em;border-bottom:1px solid var(--base-color-lighter);position:sticky;top:0;z-index:1;background-color:var(--yellow-background-lighter)}.ui-section-feed{background:var(--yellow-background-lighter)}.ui-section-feed .ui-layout-grid{align-items:flex-start}.ui-section-feed .ui-text-note{text-align:left;font-size:.9em}.ui-container-feed{text-align:left;margin-top:1em;margin-bottom:2em;justify-items:left}.ui-container-feed.ui-container-feed--hot{margin-top:2em}.ui-feed-item{display:grid;color:var(--base-color);grid-template-columns:130px 1fr;align-content:start;grid-gap:0 0.5em}.ui-feed-item .ui-feed-item__og-image img{width:100%;height:auto;max-height:7em;object-fit:contain;object-position:center top}.ui-feed-item .ui-feed-item__title{font-weight:700;font-size:.9em;-webkit-line-clamp:3;-webkit-box-orient:vertical;display:-webkit-box;overflow:hidden;word-break:break-all}.ui-feed-item .ui-feed-item__title:hover{text-decoration:underline}.ui-feed-item .ui-feed-item__title:visited{color:var(--base-color-lighter)}.ui-feed-item .ui-feed-item__hatena-count{margin:.1em 0;font-size:.7em}.ui-feed-item .ui-feed-item__hatena-count img{display:inline;width:1.25em;height:1.25em;vertical-align:middle}.ui-feed-item .ui-feed-item__hatena-count span{color:var(--hatena-color);font-weight:700;vertical-align:middle}.ui-feed-item .ui-feed-item__blog-title{margin:.3em 0;font-size:.75em}.ui-feed-item .ui-feed-item__blog-title--link:hover{text-decoration:underline}.ui-feed-item .ui-feed-item__summary{font-size:.75em;margin:.3em 0;word-break:break-all;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;display:-webkit-box;color:var(--base-color-muted)}.ui-feed-item .ui-feed-item__date{color:var(--base-color-muted);font-size:.7em}@media screen and (min-width:48rem){.ui-feed-item{display:block}.ui-feed-item .ui-feed-item__og-image{display:block}.ui-feed-item .ui-feed-item__og-image img{height:9em;max-height:9em}.ui-feed-item .ui-feed-item__title{margin-top:.5em}}@media screen and (min-width:75rem){.ui-feed-item .ui-feed-item__og-image img{height:8em;max-height:8em}}.ui-section-blog{background:var(--yellow-background-lighter)}.ui-container-blog{text-align:left;margin-top:2em}.ui-blog{display:grid;color:var(--base-color);grid-template-columns:130px 1fr;align-content:start;grid-gap:0 0.5em}.ui-blog .ui-blog__og-image img{width:100%;height:auto;max-height:7em;object-fit:contain;object-position:center top}.ui-blog .ui-blog__title{display:block;font-weight:700;word-break:break-all}.ui-blog .ui-blog__title:hover{text-decoration:underline}.ui-blog .ui-blog__link{display:block;font-size:.7em;word-break:break-all;overflow:hidden;margin:.2em 0}.ui-blog .ui-blog__link:hover{text-decoration:underline}.ui-blog .ui-blog__description{font-size:.75em;margin:.3em 0;word-break:break-all;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;display:-webkit-box;color:var(--base-color-muted)}.ui-blog .ui-blog__date{color:var(--base-color-muted);font-size:.7em}@media screen and (min-width:48rem){.ui-blog{display:block}.ui-blog .ui-blog__og-image{display:block}.ui-blog .ui-blog__og-image img{width:auto;height:9em;max-height:9em}.ui-blog .ui-blog__title{margin-top:.5em}}@media screen and (min-width:75rem){.ui-blog .ui-blog__og-image img{width:auto;height:8em;max-height:8em}}.ui-container-blog-summary{text-align:left;margin-bottom:2em}.ui-blog-summary .ui-blog-summary__link{display:block;word-break:break-all;overflow:hidden;margin:.2em 0}.ui-blog-summary .ui-blog-summary__link:hover{text-decoration:underline}.ui-blog-summary .ui-blog-summary__description{margin:.3em 0;word-break:break-all;color:var(--base-color-muted)}.ui-section-footer .ui-section-footer__site-info{margin-bottom:1.5em;display:block;font-size:.9em}.ui-section-footer .ui-section-footer__site-info .ui-text-note{margin-bottom:.7em;line-height:1.4em}
</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-")</script><title>Chip Huyenのフィード｜生成AI・LLM関連テックブログRSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://r-kagaya.github.io/llm-tech-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="lazy" decoding="async" width="96" height="96"> <span class="ui-section-header__title">生成AI・LLM関連テックブログRSS</span> </a><a href="https://github.com/r-kagaya/llm-tech-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/github-mark.png" alt="GitHubロゴ" loading="lazy" decoding="async" width="96" height="96"></a></div></div></header><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div 
class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">Chip Huyen</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://huyenchip.com">https://huyenchip.com</a><p class="ui-blog-summary__description">I help companies deploy machine learning into production. I write about AI applications, tooling, and best practices.</p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2025/01/16/ai-engineering-pitfalls.html"><img 
src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2025/01/16/ai-engineering-pitfalls.html">Common pitfalls when building generative AI applications</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
As we’re still in the early days of building applications with foundation models, it’s normal to make mistakes. This is a quick note with examples of some of the most common pitfalls that I’ve seen, both from public case studies and from my personal experience. Because these pitfalls are common, if you’ve worked on any AI product, you’ve probably seen them before. 1. Use generative AI when you don&#39;t need generative AI Every time there’s a new technology, I can hear the collective sigh of senior engineers everywhere: “Not everything is a nail.” Generative AI isn’t an exception — its seemingly limitless capabilities only exacerbate the tendency to use generative AI for everything. A team pitched me the idea of using generative AI to optimize energy consumption. They fed a household’s list of energy-intensive activities and hourly electricity prices into an LLM, then asked it to create a schedule to minimize energy costs. Their experiments showed that this could help reduce a household’s ...
</div><div class="ui-feed-item__date" title="2025-01-16 00:00:00">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2025/01/07/agents.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2025/01/07/agents.html">Agents</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
Intelligent agents are considered by many to be the ultimate goal of AI. The classic book by Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach (Prentice Hall, 1995), defines the field of AI research as “the study and design of rational agents.” The unprecedented capabilities of foundation models have opened the door to agentic applications that were previously unimaginable. These new capabilities make it finally possible to develop autonomous, intelligent agents to act as our assistants, coworkers, and coaches. They can help us create a website, gather data, plan a trip, do market research, manage a customer account, automate data entry, prepare us for interviews, interview our candidates, negotiate a deal, etc. The possibilities seem endless, and the potential economic value of these agents is enormous. This section will start with an overview of agents and then continue with two aspects that determine the capabilities of an agent: tools and planning. Agents,...
</div><div class="ui-feed-item__date" title="2025-01-07 00:00:00">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/07/25/genai-platform.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/07/25/genai-platform.html">Building A Generative AI Platform</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
After studying how companies deploy generative AI applications, I noticed many similarities in their platforms. This post outlines the common components of a generative AI platform, what they do, and how they are implemented. I try my best to keep the architecture general, but certain applications might deviate. This is what the overall architecture looks like. This is a pretty complex system. This post will start from the simplest architecture and progressively add more components. In its simplest form, your application receives a query and sends it to the model. The model generates a response, which is returned to the user. There are no guardrails, no augmented context, and no optimization. The Model API box refers to both third-party APIs (e.g., OpenAI, Google, Anthropic) and self-hosted APIs. From this, you can add more components as needs arise. The order discussed in this post is common, though you don’t need to follow the exact same order. A component can be skipped if your sy...
</div><div class="ui-feed-item__date" title="2024-07-25 00:00:00">7ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/04/17/personal-growth.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/04/17/personal-growth.html">Measuring personal growth</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
My founder friends constantly think about growth. They think about how to measure their business growth and how to get to the next order of magnitude scale. If they’re making $1M ARR today, they think about how to get to $10M ARR. If they have 1,000 users today, they think about how to get to 10,000 users. This made me wonder if/how people are measuring personal growth. I don’t want to use metrics like net worth or the number of followers, because that’s not what I live for. After talking with a lot of friends, I found three interesting metrics: rate of change, time to solve problems, and number of future options. Some friends told me they find this blog post mildly sociopathic. Why do I have to measure everything? Life is to be lived, not to be measured. As someone lowkey fascinated by numbers, I don’t see why measuring and living have to be mutually exclusive – measuring often helps me live better – but I see where they come from. This post is more of a thought exercise than a rigoro...
</div><div class="ui-feed-item__date" title="2024-04-17 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/03/14/ai-oss.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/03/14/ai-oss.html">What I learned from looking at 900 most popular open source AI tools</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
[Hacker News discussion, LinkedIn discussion, Twitter thread] Four years ago, I did an analysis of the open source ML ecosystem. Since then, the landscape has changed, so I revisited the topic. This time, I focused exclusively on the stack around foundation models. The full list of open source AI repos is hosted at llama-police. The list is updated every 6 hours. You can also find most of them on my cool-llm-repos list on GitHub. Data I searched GitHub using the keywords gpt, llm, and generative ai. If AI feels so overwhelming right now, it’s because it is. There are 118K results for gpt alone. To make my life easier, I limited my search to the repos with at least 500 stars. There were 590 results for llm, 531 for gpt, and 38 for generative ai. I also occasionally checked GitHub trending and social media for new repos. After MANY hours, I found 896 repos. Of these, 51 are tutorials (e.g. dair-ai/Prompt-Engineering-Guide) and aggregated lists (e.g. f/awesome-chatgpt-prompts). While thes...
</div><div class="ui-feed-item__date" title="2024-03-14 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/02/28/predictive-human-preference.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/02/28/predictive-human-preference.html">Predictive Human Preference: From Model Ranking to Model Routing</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
A challenge of building AI applications is choosing which model to use. What if we don’t have to? What if we can predict the best model for any prompt? Predictive human preference aims to predict which model users might prefer for a specific query. Human preference has emerged to be both the Northstar and a powerful tool for AI model development. Human preference guides post-training techniques including RLHF and DPO. Human preference is also used to rank AI models, as used by LMSYS’s Chatbot Arena. Chatbot Arena aims to determine which model is generally preferred. I wanted to see if it’s possible to predict which model is preferred for each query. One use case of predictive human preference is model routing. For example, if we know in advance that for a prompt, users will prefer Claude Instant’s response over GPT-4, and Claude Instant is cheaper/faster than GPT-4, we can route this prompt to Claude Instant. Model routing has the potential to increase response quality while reducing c...
</div><div class="ui-feed-item__date" title="2024-02-28 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/01/16/sampling.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/01/16/sampling.html">Generation configurations: temperature, top-k, top-p, and test time compute</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
ML models are probabilistic. Imagine that you want to know what’s the best cuisine in the world. If you ask someone this question twice, a minute apart, their answers both times should be the same. If you ask a model the same question twice, its answer can change. If the model thinks that Vietnamese cuisine has a 70% chance of being the best cuisine and Italian cuisine has a 30% chance, it’ll answer “Vietnamese” 70% of the time, and “Italian” 30%. This probabilistic nature makes AI great for creative tasks. What is creativity but the ability to explore beyond the common possibilities, to think outside the box? However, this probabilistic nature also causes inconsistency and hallucinations. It’s fatal for tasks that depend on factuality. Recently, I went over 3 months’ worth of customer support requests of an AI startup I advise and found that ⅕ of the questions are because users don’t understand or don’t know how to work with this probabilistic nature. To understand why AI’s responses ...
</div><div class="ui-feed-item__date" title="2024-01-16 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/10/10/multimodal.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/10/10/multimodal.html">Multimodality and Large Multimodal Models (LMMs)</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
For a long time, each ML model operated in one data mode – text (translation, language modeling), image (object detection, image classification), or audio (speech recognition). However, natural intelligence is not limited to just a single modality. Humans can read, talk, and see. We listen to music to relax and watch out for strange noises to detect danger. Being able to work with multimodal data is essential for us or any AI to operate in the real world. OpenAI noted in their GPT-4V system card that “incorporating additional modalities (such as image inputs) into LLMs is viewed by some as a key frontier in AI research and development.” Incorporating additional modalities to LLMs (Large Language Models) creates LMMs (Large Multimodal Models). Not all multimodal systems are LMMs. For example, text-to-image models like Midjourney, Stable Diffusion, and Dall-E are multimodal but don’t have a language model component. Multimodal can mean one or more of the following: Input and output are o...
</div><div class="ui-feed-item__date" title="2023-10-10 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/08/16/llm-research-open-challenges.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/08/16/llm-research-open-challenges.html">Open challenges in LLM research</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
[LinkedIn discussion, Twitter thread] Never before in my life had I seen so many smart people working on the same goal: making LLMs better. After talking to many people working in both industry and academia, I noticed the 10 major research directions that emerged. The first two directions, hallucinations and context learning, are probably the most talked about today. I’m the most excited about numbers 3 (multimodality), 5 (new architecture), and 6 (GPU alternatives). 1. Reduce and measure hallucinations Hallucination is a heavily discussed topic already so I’ll be quick. Hallucination happens when an AI model makes stuff up. For many creative use cases, hallucination is a feature. However, for most other use cases, hallucination is a bug. I was at a panel on LLM with Dropbox, Langchain, Elastics, and Anthropic recently, and the #1 roadblock they see for companies to adopt LLMs in production is hallucination. Mitigating hallucination and developing metrics to measure hallucination is a ...
</div><div class="ui-feed-item__date" title="2023-08-16 00:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/06/07/generative-ai-strategy.html"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/06/07/generative-ai-strategy.html">Generative AI Strategy</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
I had a lot of fun preparing the talk: “Leadership needs us to do generative AI. What do we do?” for Fully Connected. The idea for the talk came from many conversations I’ve had recently with friends who need to figure out their generative AI strategy, but aren’t sure what exactly to do. This talk is a simple framework to explore what to do with generative AI. Many ideas are still being fleshed out. I hope to convert this into a proper post when I have more time. In the meantime, I’d love to hear from your experience through this process. I couldn’t figure out how to make the slides centered on the page. You might want to download the slides. Thanks everyone who responded to my post and shared your thoughts on what I should include in the talk. Thanks Kyle Gallatin, Goku Mohandas, Han-chung Lee, and Jamie de Guerre for thoughtful feedback on the talk.</div><div class="ui-feed-item__date" title="2023-06-07 00:00:00">2年前</div></div></div></div></div></section></main><footer 
role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-layout-column-6 ui-layout-column-center"><div class="ui-component-cta ui-layout-flex ui-section-footer__site-info"><p class="ui-text-note">このサイトは<br>記事を読んでその企業の技術・カルチャーを知れることや<br>質の高い技術情報を得られることを目的としています。</p><p class="ui-text-note">追加したいブログがある場合は<br><a href="https://github.com/r-kagaya/llm-tech-blog-rss-feed#%E3%82%B5%E3%82%A4%E3%83%88%E3%81%AE%E8%BF%BD%E5%8A%A0%E6%96%B9%E6%B3%95">サイトの追加方法</a> をご参照ください。</p></div></div></div><div class="ui-layout-container"><div class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/r-kagaya/"><small>@r-kagaya</small></a></p><a href="https://github.com/r-kagaya/llm-tech-blog-rss-feed/" role="link" aria-label="#" class="ui-text-note"><small>GitHub</small></a></div></div></footer></body></html>